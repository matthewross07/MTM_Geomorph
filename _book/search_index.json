[
["terrain-analyses-using-taudem.html", "Methods for: Identifying geomorphic process domains in synthetic landscapes of West Virginia, USA 1 Terrain analyses using TauDEM 1.1 Pit remove 1.2 D8 1.3 D-Infinity 1.4 Stream detection", " Methods for: Identifying geomorphic process domains in synthetic landscapes of West Virginia, USA Dr. Matthew Ross and Dr. Kristin Jaeger matt.ross(at)colostate.edu August 22, 2020 1 Terrain analyses using TauDEM This is a script that does terrain analyses using the TauDEM tool from David Tarboton at Utah State. All scripts below should be run in bash or terminal after installing TauDEM. R Code is mixed throughout to generate a final data table for analysis. Some R code is at the bottom of the script to project outlets and subset rasters. Some notes: This project evolved over the 5+ years we worked on it, and while I’ve tried to update the code to reflect my current approach, this often was too time-consuming or not worth it. As of posting this, all code works, assuming you have TauDEM installed and working. Back when this was done I was pretty bad at file tracking (still lots to learn), so lots and lots of code chunks are set to eval = FALSE to avoid rerunning time. Finally, I would probably do this in whitebox now since it runs with calls inside of R, though I found TauDEM reliable and reproducible and easy to learn. 1.1 Pit remove TauDEM has robust documentation mpiexec -n 8 pitremove -z data/in/TauNew.tif -fel data/out/newfel.tif mpiexec -n 8 pitremove -z data/in/TauOldElev.tif -fel data/out/oldfel.tif 1.2 D8 1.2.1 Flow direction with slope and flow direction mpiexec -n 8 d8flowdir -p data/out/newdir8.tif -sd8 data/out/newsd8.tif -fel data/out/newfel.tif mpiexec -n 8 d8flowdir -p data/out/olddir8.tif -sd8 data/out/oldsd8.tif -fel data/out/oldfel.tif 1.2.2 Flow accumulation mpiexec -n 8 aread8 -p data/out/newdir8.tif -ad8 data/out/newuaa8.tif mpiexec -n 8 aread8 -p data/out/olddir8.tif -ad8 data/out/olduaa8.tif 1.3 D-Infinity 1.3.1 Flowdir mpiexec -n 8 dinfflowdir -ang data/out/newinffdr.tif -slp data/out/newinfslp.tif -fel data/out/newfel.tif mpiexec -n 8 dinfflowdir -ang data/out/oldinffdr.tif -slp data/out/oldinfslp.tif -fel data/out/oldfel.tif 1.3.2 Flow accumulation mpiexec -n 7 areadinf -ang data/out/newinffdr.tif -sca data/out/newinfuaa.tif mpiexec -n 7 areadinf -ang data/out/oldinffdr.tif -sca data/out/oldinfuaa.tif 1.4 Stream detection 1.4.1 Threshold 1000 pixels = 0.1 km2 #New infinity mpiexec -n 7 threshold -ssa data/out/newinfuaa.tif -src data/out/new100inf.tif -thresh 100 #Old infinity mpiexec -n 7 threshold -ssa data/out/oldinfuaa.tif -src data/out/old100inf.tif -thresh 100 #New D8 mpiexec -n 7 threshold -ssa data/out/newuaa8.tif -src data/out/new1008.tif -thresh 100 #Old D8 mpiexec -n 7 threshold -ssa data/out/olduaa8.tif -src data/out/old1008.tif -thresh 100 #Curvature method "],
["identifying-heavily-mined-watersheds.html", "2 Identifying heavily mined watersheds 2.1 Project outlets with same projection as rasters", " 2 Identifying heavily mined watersheds The goal of othis project is to better understand how mining has altered the geomorphology of these landscapes, so we want to work in landscapes that have been heavily mined. 2.1 Project outlets with same projection as rasters library(raster) library(tidyverse) library(magrittr) library(rgdal) library(rgeos) library(shapefiles) library(maptools) library(leaflet) library(velox) library(foreach) library(snow) library(parallel) library(doParallel) library(Hmisc) 2.1.1 Convert river network into shapefile Note: All of this is using gdal/sp/etc… I would recommend using sf, s2 and terra for future approaches. As stated at beginning this project was started in 2014! This using code from John Baumgartner note that gdal and python-gdal must be installed (on linux machine) I used this network to hand select watershed outlets based on a separate layer of mining extent. I tried to capture watersheds that were &gt; 90% mined. gdal_polygonizeR &lt;- function(x, outshape=NULL, gdalformat = &#39;ESRI Shapefile&#39;, pypath=NULL, readpoly=TRUE, quiet=TRUE) { if (isTRUE(readpoly)) require(rgdal) if (is.null(pypath)) { pypath &lt;- Sys.which(&#39;gdal_polygonize.py&#39;) } if (!file.exists(pypath)) stop(&quot;Can&#39;t find gdal_polygonize.py on your system.&quot;) owd &lt;- getwd() on.exit(setwd(owd)) setwd(dirname(pypath)) if (!is.null(outshape)) { outshape &lt;- sub(&#39;\\\\.shp$&#39;, &#39;&#39;, outshape) f.exists &lt;- file.exists(paste(outshape, c(&#39;shp&#39;, &#39;shx&#39;, &#39;dbf&#39;), sep=&#39;.&#39;)) if (any(f.exists)) stop(sprintf(&#39;File already exists: %s&#39;, toString(paste(outshape, c(&#39;shp&#39;, &#39;shx&#39;, &#39;dbf&#39;), sep=&#39;.&#39;)[f.exists])), call.=FALSE) } else outshape &lt;- tempfile() if (is(x, &#39;Raster&#39;)) { require(raster) writeRaster(x, {f &lt;- tempfile(fileext=&#39;.tif&#39;)}) rastpath &lt;- normalizePath(f) } else if (is.character(x)) { rastpath &lt;- normalizePath(x) } else stop(&#39;x must be a file path (character string), or a Raster object.&#39;) system2(&#39;python&#39;, args=(sprintf(&#39;&quot;%1$s&quot; &quot;%2$s&quot; -f &quot;%3$s&quot; &quot;%4$s.shp&quot;&#39;, pypath, rastpath, gdalformat, outshape))) if (isTRUE(readpoly)) { shp &lt;- readOGR(dirname(outshape), layer = basename(outshape), verbose=!quiet) return(shp) } return(NULL) } sn.new.inf &lt;- raster(&#39;data/out/new1000.tif&#39;) old.outlines &lt;- readOGR(&#39;data/in/shapefile&#39;,&#39;FinalWshed_All_Whole&#39;) %&gt;% spTransform(.,projection(sn.new.inf)) sn.1000 &lt;- crop(sn.new.inf,extent(old.outlines)) sn.1000[sn.1000 &lt; 1] &lt;- NA sn.1000.shp &lt;- gdal_polygonizeR(sn.1000) sn.1000.clip &lt;- sn.1000.shp[old.outlines,] sn.1000.clip &lt;- gUnaryUnion(sn.1000.clip, id = sn.1000.clip$DN) sn.1000.clip$name &lt;- &#39;data&#39; # writeOGR(sn.1000.clip,&#39;data/in/shapefile&#39;,&#39;sn.1000.clip&#39;,driver=&#39;ESRI Shapefile&#39;,overwrite_layer = T) old.inf &lt;- raster(&#39;old100.tif&#39;) old.inf[old.inf&lt;1] &lt;- NA old.1000.shp &lt;- gdal_polygonizeR(old.inf) old.100.clip &lt;- old.1000.shp[old.outlines,] old.100.clip &lt;- gUnaryUnion(old.100.clip,id=old.100.clip$DN) old.100.clip$name &lt;- &#39;data&#39; # writeOGR(old.100.clip,&#39;data/in/shapefile&#39;,&#39;old.100.clip&#39;,driver=&#39;ESRI Shapefile&#39;) 2.1.2 Reproject outlets to same projection as rasters #Match outlet projections to raster data outs &lt;- readOGR(&#39;data/in/shapefile/SubSheds.kml&#39;,&#39;Sub Sheds&#39;,stringsAsFactors=F) %&gt;% spTransform(.,CRS=CRS(&#39;+init=epsg:26917&#39;)) outs &lt;- outs[,1] outs$Id &lt;- 1:nrow(outs) outs &lt;- outs[,2:1] writeOGR(outs,&#39;data/in/shapefile&#39;,&#39;approxnew&#39;,driver=&#39;ESRI Shapefile&#39;,overwrite_layer = T) "],
["delineate-watersheds-for-analysis.html", "3 Delineate watersheds for analysis 3.1 Stack and cutup rasters to smaller extents for later analysis in r. 3.2 Convert raster data to data frames", " 3 Delineate watersheds for analysis Now that we have identified watersheds in the previous step, we will use those pour points to: Delineate watersheds Prepare the terrain metrics within these watersheds for analysis in R Save these outputs in a compressed file. #New Infinity mpiexec -n 7 areadinf -ang data/out/newinffdr.tif -o data/in/shapefile/approxnew.shp -sca newshedinf.tif mpiexec -n 7 aread8 -p data/out/newdir8.tif -o data/in/shapefile/approxnew.shp -ad8 newshed8.tif mpiexec -n 7 areadinf -ang data/out/oldinffdr.tif -o data/in/shapefile/approxnew.shp -sca oldshedinf.tif mpiexec -n 7 aread8 -p data/out/olddir8.tif -o data/in/shapefile/approxnew.shp -ad8 oldshed8.tif 3.1 Stack and cutup rasters to smaller extents for later analysis in r. #Using a new faster raster library called Velox #Setup readin paths and crop extents and name order and empty lists #Upslop accumulated area data uaa.paths &lt;- paste0(&#39;data/out/&#39;,c(&#39;newshedinf.tif&#39;, &#39;oldshedinf.tif&#39;,&#39;newshed8.tif&#39;,&#39;oldshed8.tif&#39;)) #Slope data. slope.paths &lt;- paste0(&#39;data/out/&#39;,c(&#39;newinfslp.tif&#39;,&#39;oldinfslp.tif&#39;,&#39;newsd8.tif&#39;,&#39;oldsd8.tif&#39;)) #Elevation data. e.paths &lt;- paste0(&#39;data/in/&#39;,c(&#39;TauNew.tif&#39;,&#39;TauNew.tif&#39;,&#39;TauOldElev.tif&#39;,&#39;TauOldElev.tif&#39;) #Names for where elevation profiles come from (matched with current shed boundaries or not? New.e.new means New elevatio profiles with new shed boundaries. New.e.old means new elevation with old shed boundaries) e.names &lt;- c(&#39;New.e.new&#39;,&#39;New.e.old&#39;,&#39;Old.e.new&#39;,&#39;Old.e.old&#39;) #Read in raster outlines sheds &lt;- raster(uaa.paths[1]) %&gt;% crop(.,extent(400000,470000,4150000,4230000)) oldsheds&lt;- raster(uaa.paths[3]) %&gt;% crop(.,extent(400000,470000,4150000,4230000)) #Set all values to 1 sheds[sheds &gt; 0] &lt;- 1 #Turn these into shapefiles shd.shp &lt;- gdal_polygonizeR(sheds) #Buffer out by 500m to include any ridge changes and reproject to outlet projeciton shd.shp.buf &lt;- gBuffer(shd.shp,width=100) %&gt;% spTransform(.,projection(outs)) %&gt;% disaggregate(.) %&gt;% SpatialPolygonsDataFrame(.,data=data.frame(id=1:10)) ##Plot shd.shp.buf to see if the buffered area includes old watersheds # plot(shd.shp.buf) # plot(oldsheds,col=&#39;black&#39;,add=T) #Join these shapefiles to the outlets to get the names (ref or not ref) shd.names &lt;- over(shd.shp.buf,outs) shd.shp.names &lt;- spCbind(shd.shp.buf,shd.names) #save(shd.shp.names,file=&#39;data/out/watersheds.RData&#39;) #Setup storage lists uaa.stack &lt;- list() slope.stack &lt;- list() e.stack &lt;- list() esu.stacked &lt;- list() #Evaluate on 7 cores cl &lt;- makeCluster(3) registerDoParallel(cl,cores=3) all.list &lt;- foreach(i = 1:nrow(shd.names)) %dopar% { library(raster) library(rgdal) library(magrittr) #Read in each Watershed outline to trim data shape &lt;- shd.shp.names[shd.shp.names$Name == shd.names$Name[i],] for(j in 1:length(uaa.paths)){ #Read in watershed delineations and crop to single watershed shed &lt;- raster(uaa.paths[j]) %&gt;% crop(.,shape) #Store this cropped watershed uaa tif in a list uaa.stack[[j]] &lt;- shed #Read in slope raster and crop slope &lt;- raster(slope.paths[j]) %&gt;% crop(.,shape) #Set Slope values outside of watershed to NA slope[is.na(shed)] &lt;- NA #Store in slope stack slope.stack[[j]] &lt;- slope #Samesies with elevation e &lt;- raster(e.paths[j]) %&gt;% crop(.,shape) e[is.na(shed)] &lt;- NA e.stack[[j]] &lt;- e } esu.stacked[[i]] &lt;- stack(c(e.stack,slope.stack,uaa.stack)) %&gt;% trim(.) } endCluster() names(all.list) &lt;- shd.names$Name #save(all.list, file=&#39;data/out/ras.stack.ref.RData&#39;) 3.2 Convert raster data to data frames #Loads in all list which is a list of all sites load(&#39;data/out/ras.stack.ref.RData&#39;) library(doParallel) #to do parallel processing library(parallel) # to register parallel processing library(foreach) # to do parallel processing as a forloop #Evaluate on 7 cores cl &lt;- makeCluster(3) #make a cluster with 3 cores registerDoParallel(cl,cores=3) #tell parallel processor to use 3 cores stack.list &lt;- foreach(i=1:length(all.list)) %dopar% { library(raster) library(dplyr) library(magrittr) l &lt;- extract(all.list[[i]]) %&gt;% as.data.frame(.) %&gt;% mutate(Site = shd.names$Name[i]) } endCluster() stack.df &lt;- do.call(&#39;rbind&#39;,stack.list) names(stack.df)[1:4] &lt;- e.names head(stack.df) #Name the rows of this wide data frame save(stack.df,file=&#39;data/out/UAA.E.Slope.Ref.RData&#39;) "],
["analysis-and-figures.html", "4 Analysis and Figures 4.1 A note on PROJ 4 and PROJ 6 4.2 Data Prep 4.3 Figure 1 - Mining demonstration 4.4 Figure 3 Study Map", " 4 Analysis and Figures 4.1 A note on PROJ 4 and PROJ 6 I’m not an expert on all the implications of the migration from PROJ 4 to PROJ 6, however it does impact our analysis, at least in the behavior of the code. This analysis was all done in EPSG:26917, which in the older version of raster (pre-2020) would give no warnings or errors. Since then, raster gdal and a bunch of other packages have migrated the projection system to PROJ 6 and now when we load these old rasters in we get a warning: Warning message: In showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\") : Discarded datum Unknown based on GRS80 ellipsoid in CRS definition, but +towgs84= values preserved This warning does not affect the performance, expected behavior, or analyses in anyway, but it’s important to note. For future analyses we need to figure out how to migrate this projection to raster so that it works well (or terra). 4.2 Data Prep knitr::opts_chunk$set(eval = F) 4.2.1 Convert data to long format In the following code chunk I load in the terrain analysis data convert it into long data and make sensible column names. I then save this file so I don’t have to perform the operations again. #Add an index column stack.df$index &lt;- 1:nrow(stack.df) #Gather data into one long data frame long.df &lt;- stack.df %&gt;% gather(Key,value,-Site,-index,na.rm=T) %&gt;% #Fix whiteoak reference name (currently labeld just white) mutate(Site=ifelse(Site==&#39;WhiteRef&#39;,&#39;WhiteOakRef&#39;,Site)) %&gt;% #Create a column with watershed delineation data (is it old elevation shed or new elevation shed?) #This information is the last word in the key column (new.e.new = new elevation profile with new watershed boundary, old.e.new = old elevation profile with new watershed boundary) mutate(shed.type= ifelse(grepl(&#39;\\\\.&#39;,Key),str_split_fixed(Key,&#39;\\\\.&#39;,n=3)[,3],NA)) %&gt;% mutate(elev.data= ifelse(grepl(&#39;\\\\.&#39;,Key),str_split_fixed(Key,&#39;\\\\.&#39;,n=3)[,1],NA)) %&gt;% #Column to show what flow direction algorithm was used for calcuation mutate(fdr.type = ifelse(grepl(&#39;8&#39;,Key),&#39;f.8&#39;,&#39;f.inf&#39;)) %&gt;% #Elevation does not have a flow direction associated with it mutate(fdr.type = ifelse(!is.na(shed.type),&#39;None&#39;,fdr.type)) %&gt;% #What kind of data is in the column? UAA Slope or Elev? mutate(Data=ifelse(grepl(&#39;shed&#39;,Key),&#39;UAA&#39;,&#39;Slope&#39;)) %&gt;% mutate(Data=ifelse(!is.na(shed.type),&#39;Elev&#39;,Data)) %&gt;% #Relabel &#39;new&#39; as post-mining and old as pre-mining mutate(Data.Source = ifelse(grepl(&#39;new&#39;,Key) &amp; !grepl(&#39;Ref&#39;,Site),&#39;Current&#39;,&#39;Historic&#39;)) %&gt;% #Split sites between reference and mined mutate(Type = ifelse(grepl(&#39;Ref&#39;,Site),&#39;Unmined&#39;,&#39;Mined&#39;)) %&gt;% #Rename treaments for reference to reflect historic dem and current dem mutate(Data.Source=ifelse(grepl(&#39;Ref&#39;,Site) &amp; grepl(&#39;new&#39;,Key),&#39;Current&#39;,Data.Source)) %&gt;% mutate(Data.Source=ifelse(grepl(&#39;Ref&#39;,Site) &amp; grepl(&#39;old&#39;,Key),&#39;Historic&#39;,Data.Source)) %&gt;% #Make new column with huc12 watershed name mutate(Watershed = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) dat.check &lt;- long.df %&gt;% group_by(Watershed,Type,Data.Source,Site) %&gt;% dplyr::summarize(length=n()) #save(long.df,file=&#39;data/out/Long.DF.RData&#39;) 4.3 Figure 1 - Mining demonstration The images from this figure come from an aerial flight done by Duke University. The DEM generation is below. old.e &lt;- raster(&#39;data/in/olddem_Clip1.tif&#39;) new.e &lt;- raster(&#39;data/in/lidshedDEMcl1.tif&#39;) summary(new.e) #Read in Elev Rasters new.e &lt;- raster(&#39;lidshedDEMcl1.tif&#39;) old.e &lt;- raster(&#39;olddem_Clip1.tif&#39;) #Set min surface value new.e[is.na(new.e)] &lt;- minValue(new.e) old.e[is.na(old.e)] &lt;- minValue(old.e) #Setup old elevation profile matrix old.m &lt;- as.matrix(old.e) old.x &lt;- 10*1:nrow(old.m) old.y &lt;- 10*1:ncol(old.m) old.z &lt;- 2*as.matrix(old.m) #Setup new elevation profile as matrix new.m &lt;- as.matrix(new.e) new.x &lt;- 10*1:nrow(new.m) new.y &lt;- 10*1:ncol(new.m) new.z &lt;- 2*as.matrix(new.m) persp(old.x,old.y,old.z,scale=F,box=F,theta=-10,phi=30) 4.4 Figure 3 Study Map # Functino get outline of st_envelope = function(x) st_as_sfc(st_bbox(x)) load(&#39;data/out/watersheds.RData&#39;) watersheds &lt;- st_as_sf(shd.shp.names,crs=26917) %&gt;% mutate(Site = c(&#39;White Oak&#39;,&#39;White Oak&#39;,&#39;Laurel&#39;, &#39;Laurel&#39;,&#39;Spruce&#39;,&#39;Spruce&#39;,&#39;Mud&#39;,&#39;Ben&#39;,&#39;Mud&#39;,&#39;Ben&#39;), Type=c(&#39;Mined&#39;,&#39;Reference&#39;,&#39;Reference&#39;,&#39;Mined&#39;,&#39;Reference&#39;,&#39;Mined&#39;,&#39;Reference&#39;,&#39;Reference&#39;,&#39;Mined&#39;,&#39;Mined&#39;)) %&gt;% mutate(CENTROID = map(geometry, st_centroid), COORDS = map(CENTROID, st_coordinates), COORDS_X = map_dbl(COORDS, 1), COORDS_Y = map_dbl(COORDS, 2)) boundary &lt;- st_envelope(st_buffer(watersheds,10000)) #No idea why the extent object wouldn&#39;t work. e2010 &lt;- raster(&#39;data/in/TauNew.tif&#39;) %&gt;% crop(.,extent(411446,460186,4154384,4221224)) %&gt;% aggregate(.,10) eobj &lt;- rasterToPoints(e2010) %&gt;% as_tibble() #Weird rule where fill =T makes this possible to convert to a sf object. us_states wv &lt;- us_states() %&gt;% filter(stusps %in% c(&#39;WV&#39;,&#39;VA&#39;,&#39;OH&#39;,&#39;PA&#39;,&#39;DE&#39;,&#39;MD&#39;,&#39;NJ&#39;,&#39;KY&#39;)) %&gt;% st_transform(.,26917) dc &lt;- us_cities() %&gt;% filter(grepl(&#39;Washington&#39;,city)) %&gt;% filter(grepl(&#39;District&#39;,state_name)) %&gt;% st_transform(.,26917) wv.inset &lt;- ggplot() + geom_sf(data=wv) + theme(panel.grid.major = element_line(color=&#39;transparent&#39;)) + geom_sf(data=boundary,color=&#39;red&#39;,fill=NA,size=2) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), panel.border=element_blank()) + geom_sf(data = dc, size =5) + geom_sf_text(data = wv, aes(label = state_abbr), size = 5, check_overlap = T) + xlim(269751,1019051) wv.inset wv.dem &lt;- ggplot() + geom_tile(data=eobj,aes(x=x,y=y,fill=TauNew)) + theme_few(base_size=14) + theme(panel.grid.major = element_line(color=&#39;transparent&#39;)) + geom_sf(data=watersheds,aes(color=Type),fill=NA,size=1) + scale_color_manual(values=c(&#39;blue&#39;,&#39;purple4&#39;),name=&#39;&#39;,guide=F) + scale_fill_gradient2(high=&#39;blue2&#39;,low=&#39;red2&#39;,mid=&#39;gray70&#39;,midpoint=600,name=&#39;Elev. (m)&#39;)+ xlab(&#39;&#39;) + ylab(&#39;&#39;) + theme(legend.position=c(0.85,0.6)) + geom_text(data=watersheds %&gt;% filter(Type==&#39;Reference&#39;),aes(x=COORDS_X,y=COORDS_Y,label=Site),nudge_x=3500, nudge_y=3000,size=3.5) png(filename=&#39;Figures2018/fig3_studymap.png&#39;,width=5.9,height=6.3, units = &#39;in&#39;, res = 300) vp &lt;- viewport(width=0.35,height=0.4,x=0.73,y=0.25) print(wv.dem) print(wv.inset,vp=vp) dev.off() "],
["raw-site-summaries.html", "5 Raw site summaries 5.1 Percent mining 5.2 Total summary", " 5 Raw site summaries Summary statistics (median elevation, total relief, etc…) for each watershed. 5.1 Percent mining While we attempted to capture control watersheds that were entirely unmined and mined watersheds that were &gt; 80% mined, there is still variation around the amount of mining in each watershed. Here we use data from a paper by Andrew Pericack and others to find when and where mining occured and we use that layer to asses the mining coverage in each watershed as of 2011, when the post-mining watersheds were generated. #Read in mining detection layer from Pericack et al., 2018 first.mined &lt;- raster(&#39;data/in/FirstMinedCamp.tif&#39;) #The first raster in the list of rasters (all list) is the elevation profile #of the current watershed delineation. Use this to get % mining for each site #Use foreach to speedup the operation. Using 3 cores instead of one cl &lt;- makeCluster(8) #Register the cores (starts independent R Sessions) registerDoParallel(cl,cores=8) #Run a foreach loop that stores results in a list (pmine.list) pmine.list &lt;- foreach(i=1:length(all.list)) %dopar% { #Have to load in the important libraries for each session library(raster) library(tidyverse) library(rgeos) #Read in the raw elevation profile (first in the list) ras.raw &lt;- all.list[[i]][[1]] #Project the raster into the first.mined raster projection ras &lt;- projectRaster(ras.raw,crs=projection(first.mined)) #Crop the mined raster mine.ras &lt;- first.mined %&gt;% crop(.,ras) #Project the raster resolution onto the mine resolution (from 10 to 30m) ras.res &lt;- projectRaster(ras,mine.ras) #Mask out the areas outside of the watershed mine.mask &lt;- raster::mask(mine.ras,ras.res) #Get the number of mined pixels ras.area = length(ras.res[!is.na(ras.res)]) #Get the percent mining (mined pixels/total pixels) mine.area = length(mine.mask[mine.mask &lt; 2012]) pmine=mine.area/ras.area #Store this as a data frame. dat &lt;- tibble(pmine=pmine, Site=names(all.list)[[i]], area=round(length(ras.raw[!is.na(ras.raw)])*100/(1000*1000),1)) } #End the foreach loop stopCluster(cl) #Cast the data into a sensible data frame pmine.dat &lt;- do.call(&#39;rbind&#39;,pmine.list) %&gt;% mutate(Site=gsub(&#39;WhiteRef&#39;,&#39;WhiteOakRef&#39;,Site)) %&gt;% mutate(pmine=round(pmine,2)*100) %&gt;% dplyr::select(Site,pmine) %&gt;% arrange(Site) 5.1.1 Elevation The elevation profiles of the watersheds change following mining. Summary statistics on changes are calculated here. #Summarize stats by watershed. elev.summary &lt;- long.df %&gt;% filter(Data == &#39;Elev&#39;) %&gt;% filter(Key %in% c(&#39;Old.e.old&#39;,&#39;New.e.new&#39;)) %&gt;% group_by(Site,Watershed,Type,Data.Source) %&gt;% dplyr::summarize(max=max(value), min=min(value), median=round(median(value),0), mean=mean(value), sd=sd(value), area=round(n()*100/(1000*1000),2))%&gt;% #km2 mutate(relief=max-min) #Turn the above long dataset into a wide format. e.wide &lt;- elev.summary %&gt;% ungroup(.) %&gt;% dplyr::select(Site,Type,Data.Source,mean) %&gt;% spread(Data.Source,mean) %&gt;% arrange(Site) %&gt;% mutate(elev.change= Current/Historic)%&gt;% rename(Current.elev=Current,Historic.elev=Historic) #Get a relief summary r.wide &lt;- elev.summary %&gt;% ungroup(.) %&gt;% dplyr::select(Site,Type,Data.Source,relief) %&gt;% spread(Data.Source,relief) %&gt;% arrange(Site) %&gt;% mutate(relief.change= Current/Historic)%&gt;% rename(Current.relief=Current,Historic.relief=Historic) #Get the area data from above. area.wide &lt;- elev.summary %&gt;% ungroup(.) %&gt;% dplyr::select(Site,Type,Data.Source,area) %&gt;% spread(Data.Source,area) %&gt;% arrange(Site) %&gt;% mutate(area.change= Current/Historic)%&gt;% rename(Current.area=Current,Historic.area=Historic) 5.1.2 Slope Slope changes dramatically in mining landscapes and those changes are calculated here. #Calculate summary statistics for each watershed and data type slope.summary &lt;- long.df %&gt;% filter(Data == &#39;Slope&#39;) %&gt;% filter(fdr.type==&#39;f.inf&#39;) %&gt;% group_by(Site,Watershed,Type,Data.Source) %&gt;% dplyr::summarize(max=max(value), min=min(value), median=round(median(value),2), mean=mean(value), sd=sd(value)) %&gt;% mutate(relief=max-min) #Widen that data. s.wide &lt;- slope.summary %&gt;% ungroup(.) %&gt;% dplyr::select(Site,Type,Data.Source,median) %&gt;% spread(Data.Source,median) %&gt;% mutate(slope.change= Current/Historic)%&gt;% arrange(Site) %&gt;% rename(Current.slope=Current,Historic.slope=Historic) 5.1.3 Drainage density Our previous work has identified 1000 pixels has an approximate drainage area for the initiation of channels. drainage.density &lt;- long.df %&gt;% filter(Data == &#39;UAA&#39;) %&gt;% filter(fdr.type==&#39;f.inf&#39;) %&gt;% group_by(Site,Watershed,Type,Data.Source) %&gt;% dplyr::summarize(drainage.length = length(which(value &gt; 1000)), drainage.area=n(), drainage.density=round(drainage.length/drainage.area,3)) d.wide &lt;- drainage.density %&gt;% ungroup(.) %&gt;% dplyr::select(Site,Type,Data.Source,drainage.density) %&gt;% spread(Data.Source,drainage.density) %&gt;% mutate(DD.change= Current/Historic)%&gt;% arrange(Site) %&gt;% rename(Current.DD=Current,Historic.DD=Historic) 5.2 Total summary site.summary &lt;- pmine.dat %&gt;% left_join(e.wide,by=c(&#39;Site&#39;)) %&gt;% left_join(area.wide,by=c(&#39;Site&#39;,&#39;Type&#39;)) %&gt;% left_join(s.wide,by=c(&#39;Site&#39;,&#39;Type&#39;)) %&gt;% left_join(d.wide,by=c(&#39;Site&#39;,&#39;Type&#39;)) %&gt;% left_join(r.wide,by=c(&#39;Site&#39;,&#39;Type&#39;)) %&gt;% select(Site,Type,everything()) %&gt;% mutate_if(is.numeric,round,2) flip_summary &lt;- as_tibble(cbind(nms = names(site.summary), t(site.summary))) %&gt;% mutate(nms = gsub(&#39;\\\\.&#39;,&#39; &#39;,.$nms)) write_csv(flip_summary,path=&#39;Figures2018/SiteSummary.csv&#39;) "],
["process-zones-with-slope-area-and-cumulative-area-distribution.html", "6 Process Zones with Slope Area and Cumulative Area Distribution 6.1 UAA Slope Cutting 6.2 SA Break ID 6.3 Figure 4 - SA Plots", " 6 Process Zones with Slope Area and Cumulative Area Distribution 6.1 UAA Slope Cutting #keep only f.inf data #Reference sites are slightly smaller on average so they need a smaller value for switching bin width from lots per bin (1000) to fewer (100) uaa.small &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39;) %&gt;% dplyr::filter(Data!=&#39;Elev&#39;) %&gt;% #Sites less than 6km2 get smaller cut break select(Site,Type,Data,Data.Source,value,index) %&gt;% spread(key=Data,value) %&gt;% dplyr::filter(UAA &lt;= 6*1000*1000) %&gt;% mutate(area.m2 = round(UAA*10,0)) %&gt;% group_by(Site,Data.Source) %&gt;% mutate(area.bins = ifelse(area.m2 &lt; 20000,Hmisc::cut2(area.m2,m=200),Hmisc::cut2(area.m2,m=50))) %&gt;% ungroup() %&gt;% group_by(Site,Type,Data.Source,area.bins) %&gt;% dplyr::summarize(sd.slope=sd(Slope,na.rm=T), Slope=mean(Slope), n=n(), UAA=mean(area.m2)) #only change here is cut point for switching bin width size uaa.big &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39;) %&gt;% dplyr::filter(Data!=&#39;Elev&#39;) %&gt;% select(Site,Type,Data,Data.Source,value,index) %&gt;% spread(key=Data,value) %&gt;% #Sites greater than 6km2 get smaller cut break dplyr::filter(UAA &gt; 6*1000*1000) %&gt;% mutate(area.m2 = round(UAA*10,0)) %&gt;% group_by(Site,Data.Source) %&gt;% mutate(area.bins = ifelse(area.m2 &lt; 40000,Hmisc::cut2(area.m2,m=200),Hmisc::cut2(area.m2,m=50))) %&gt;% group_by(Site,Type,Data.Source,area.bins) %&gt;% dplyr::summarize(sd.slope=sd(Slope,na.rm=T), Slope=mean(Slope), n=n(), UAA=mean(area.m2)) uaa &lt;- bind_rows(uaa.small,uaa.big) %&gt;% filter(!is.na(Slope)) 6.1.1 Slope Area Standard Deviation Plots library(ggthemes) pdf(file=&#39;figures2018/SA.SD.pdf&#39;,width=10,height=5) uaa %&gt;% ungroup(.) %&gt;% mutate(Site = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) %&gt;% ggplot(aes(x=UAA,y=sd.slope,color=Data.Source)) + geom_point() + facet_grid(Type ~ Site) + scale_colour_few() + ylab(&#39;SD Slope (m/m)&#39;) + theme(legend.position=&#39;top&#39;,legend.direction = &#39;horizontal&#39;) + scale_y_log10(limits=c(0.01,1)) + xlab(expression(paste(&#39;Area (&#39;,m^2,&#39;)&#39;))) + scale_x_log10(breaks=trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) dev.off() ##SA Derivative and Smoothing Detecting zone changes with the raw data detects too many spurious changes related to simple variability. Here we smooth the data using a simple LOESS spline. Then we detect process zones on the smoothed data. #Make a dataframe with seamless UAA for derivation #This changed a lot since last time, tibble update? mac vs linux? full.uaa &lt;- 10^seq(2,7,.01) %&gt;% list(.) myloess &lt;- function(data){ mod &lt;- loess(log10(Slope) ~ log10(UAA),span=0.4,data=data) } uaa.nest &lt;- uaa %&gt;% group_by(Site,Type,Data.Source) %&gt;% nest() %&gt;% mutate(mods=purrr::map(data,myloess)) %&gt;% as_tibble() uaa.seam &lt;- uaa.nest %&gt;% select(-mods,-data) %&gt;% mutate(UAA=full.uaa) %&gt;% unnest(c(UAA)) %&gt;% group_by(Site,Type,Data.Source) %&gt;% nest() %&gt;% rename(newdata=data) %&gt;% full_join(uaa.nest,by=c(&#39;Site&#39;,&#39;Type&#39;,&#39;Data.Source&#39;)) %&gt;% mutate(pred=map2(mods,newdata,predict)) %&gt;% unnest(c(newdata,pred)) %&gt;% mutate(pred=10^pred) %&gt;% na.omit(.) uaa.dif &lt;- uaa.seam %&gt;% group_by(Site,Type,Data.Source) %&gt;% arrange(desc(UAA)) %&gt;% mutate(derv=c(NA,diff(log10(pred))/(diff(log10(UAA))))) %&gt;% ungroup() 6.2 SA Break ID #Using the derivitave data we can automate most of the slope breaks library(strucchange) #Winner winner chicken dinner! #Frist breaks are befrore 10^4 by visual inspection and lit values. #First minimum is generally the biggest minimum but not for all sites particularly post-mining hillslope.breaks &lt;- uaa.dif %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(max.mod = max(pred,na.rm=T)) %&gt;% filter(pred == max.mod) %&gt;% arrange(Site,Type,Data.Source,UAA) %&gt;% mutate(breaks = c(&#39;b1&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA,brk.derv=derv) #Find the alluvial break which is where the UAA Slope plot rolls over in the dervative space this after the break 2 minimum and at the next rolling maximum. This is always before 10^4.5 by visual inspection mybreaks &lt;- function(sa.data){ sa.data &lt;- sa.data %&gt;% filter(!is.na(pred)) %&gt;% filter(UAA &gt; 0) %&gt;% arrange(UAA) bkpt &lt;- Fstats(log10(sa.data$pred) ~ log10(sa.data$UAA), from=0.4) bk.points &lt;- sa.data %&gt;% filter(index %in% bkpt$breakpoint) %&gt;% select(index,UAA, derv) return((bk.points)) } alluvial.breaks &lt;- uaa.dif %&gt;% left_join(hillslope.breaks,by=c(&#39;Data.Source&#39;,&#39;Site&#39;,&#39;Type&#39;)) %&gt;% filter(UAA &gt;= value) %&gt;% filter(UAA &lt; 10^4) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(index=1:n()) %&gt;% nest() %&gt;% mutate(alluvials=purrr::map(data,mybreaks)) %&gt;% unnest(alluvials) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(breaks=c(&#39;b2&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA,brk.derv=derv) fluvial.breaks &lt;- uaa.dif %&gt;% left_join(alluvial.breaks,by=c(&#39;Data.Source&#39;,&#39;Site&#39;,&#39;Type&#39;)) %&gt;% filter(UAA &gt;= value) %&gt;% filter(UAA &lt; 10^5.5) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(index=1:n()) %&gt;% nest() %&gt;% mutate(alluvials=purrr::map(data,mybreaks)) %&gt;% unnest(alluvials) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(breaks=c(&#39;b3&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA,brk.derv=derv) sa.breaks&lt;- bind_rows(hillslope.breaks,alluvial.breaks,fluvial.breaks) %&gt;% arrange(Site,Data.Source,value) sa.brk.wide &lt;- sa.breaks %&gt;% dplyr::select(-brk.derv) %&gt;% spread(key=breaks,value=value) sa.mine.breaks &lt;- sa.breaks %&gt;% filter(Type==&#39;Mined&#39;) %&gt;% arrange(Site,Data.Source,Type) %&gt;% mutate(logb=log10(value)) sa.unmine.breaks &lt;- sa.breaks %&gt;% filter(Type!=&#39;Mined&#39;) %&gt;% arrange(Site,Data.Source,Type) #Write out the breaks write_csv(sa.breaks,path=&#39;Figures2018/sa.breaks.csv&#39;) 6.2.1 Region slopes uaa.brk &lt;- uaa %&gt;% left_join(sa.brk.wide,by=c(&#39;Site&#39;,&quot;Data.Source&quot;,&#39;Type&#39;)) sa.zone.lm &lt;- function(sa.data){ mod &lt;- lm(log10(Slope) ~ log10(UAA),data=sa.data) keys &lt;- tibble(adj.r.squared=glance(mod)$adj.r.squared, p.value=glance(mod)$p.value, reg.slope=tidy(mod)$estimate[2]) return(keys) } sa.z2&lt;- uaa.brk %&gt;% filter(UAA &gt; b1 &amp; UAA &lt; b2) %&gt;% group_by(Site,Data.Source,Type) %&gt;% nest() %&gt;% mutate(zone = &#39;z2&#39;) %&gt;% mutate(mods = map(data,sa.zone.lm)) %&gt;% unnest(mods) %&gt;% select(-data) %&gt;% arrange(Site,Data.Source) sa.z23 &lt;- uaa.brk %&gt;% filter(UAA &gt; b1 ) %&gt;% group_by(Site,Data.Source,Type) %&gt;% nest() %&gt;% mutate(zone = &#39;z23&#39;) %&gt;% mutate(mods = map(data,sa.zone.lm)) %&gt;% unnest(mods) %&gt;% select(-data) %&gt;% arrange(Site,Data.Source) sa.z3 &lt;- uaa.brk %&gt;% filter(UAA &gt; b2 &amp; UAA &lt; b3) %&gt;% group_by(Site,Data.Source,Type) %&gt;% nest() %&gt;% mutate(zone = &#39;z4&#39;) %&gt;% mutate(mods = map(data,sa.zone.lm)) %&gt;% unnest(mods) %&gt;% select(-data) sa.z4 &lt;- uaa.brk %&gt;% filter(UAA &gt; b3) %&gt;% group_by(Site,Data.Source,Type) %&gt;% nest() %&gt;% mutate(zone = &#39;z4&#39;) %&gt;% mutate(mods = map(data,sa.zone.lm)) %&gt;% unnest(mods) %&gt;% select(-data) zone.regressions &lt;- bind_rows(sa.z2,sa.z3,sa.z23,sa.z4) write_csv(zone.regressions,path=&#39;Figures2018/sa.zone.regressions.csv&#39;) 6.3 Figure 4 - SA Plots #Load in field and satellite channel head measurements # This loads in a data.frame called fld which is field measurements of # channel heads, and another one called sw which we won&#39;t use here # # #Load in field channel heads channel_heads &lt;- read_csv(&#39;data/in/channel_heads.csv&#39;) sa.breaks$Site &lt;- gsub(&#39;Ref&#39;,&#39;&#39;,sa.breaks$Site) sa.all &lt;- uaa %&gt;% select(Site,Type,Data.Source,UAA,Slope) %&gt;% ungroup() %&gt;% mutate(Site = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) %&gt;% ggplot(.,aes(x=UAA,y=Slope,color=interaction(Data.Source,Type))) + geom_point(size=1) + stat_smooth(method=&#39;loess&#39;,span=0.4,se=F) + geom_vline(data=sa.breaks,aes(xintercept=value,color=interaction(Data.Source,Type))) + facet_grid(Type~Site,scales=&#39;free_y&#39;) + geom_point(data = channel_heads,aes(fill = Channel), pch = 22, color = &#39;black&#39;) + scale_color_manual(name=&#39;Data Source&#39;,values=c(&#39;red&#39;,&#39;blue&#39;,&#39;Orange3&#39;,&#39;Purple4&#39;)) + theme(legend.position=&#39;top&#39;,legend.direction=&#39;horizontal&#39;, legend.box = &#39;vertical&#39;) + scale_fill_manual(name = &#39;Channel heads&#39;, values = c(reds,&#39;#ffba00&#39;)) + ylab(&#39;Slope (m/m)&#39;) + xlab(expression(paste(&#39;Upslope Accumulated Area (&#39;,m^2,&#39;)&#39;))) + scale_x_log10(breaks=trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + scale_y_log10(limits=c(0.01,1),breaks=c(0.01,0.1,1)) sa.all pdf(file=&#39;Figures2018/SA.All.pdf&#39;,width=10,height=6) sa.all dev.off() "],
["cumulative-area-distribution.html", "7 Cumulative area distribution 7.1 Cad breaks 7.2 UAA Density", " 7 Cumulative area distribution #Cut uaa into a sequential cad with a equally spaced sequence (equal in log space) cad &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39;) %&gt;% dplyr::filter(Data!=&#39;Elev&#39;) %&gt;% #Sites less than 6km2 get smaller cut break select(Site,Type,Data,Data.Source,value,index) %&gt;% spread(key=Data,value) %&gt;% mutate(area.m2 = round(UAA*10,2)) %&gt;% group_by(Site,Data.Source) %&gt;% mutate(area.bins = cut(area.m2,breaks=unique(area.m2)))%&gt;% ungroup() %&gt;% group_by(Site,Type,Data.Source,area.bins) %&gt;% dplyr::summarize(UAA=mean(area.m2,na.rm=T), UAA.sd = sd(area.m2,na.rm=T)) %&gt;% group_by(Site,Type,Data.Source,UAA) %&gt;% summarise(Freq=n()) %&gt;% arrange(Site,Type,Data.Source,desc(UAA)) %&gt;% mutate(Cume_Freq=(cumsum(Freq)/sum(Freq))) %&gt;% mutate(revuaa=rev(UAA)) %&gt;% mutate(smooth.freq=runmed(Cume_Freq,5)) 7.1 Cad breaks mycad.breaks &lt;- function(cad.data){ cad.model &lt;- cad.data %&gt;% filter(UAA &gt; 0) %&gt;% arrange(UAA) bkpt &lt;- Fstats(log10(cad.model$Cume_Freq) ~ log10(cad.model$UAA),from=0.5) bk.points &lt;- cad.data %&gt;% filter(index %in% bkpt$breakpoint) return((bk.points)) } #Data density for CAD is much higher than SA so this takes ~ 10 minutes to run #Shortened the runtime by trimming data to a region that captures all breaks across all sites when run across full data. diffusecad &lt;- cad %&gt;% filter(UAA &lt; 5000 ) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(index=1:n()) %&gt;% nest() %&gt;% mutate(hills=purrr::map(data,mycad.breaks)) %&gt;% unnest(hills) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(breaks=c(&#39;b1&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA) incisioncad &lt;- cad %&gt;% left_join(diffusecad,by=c(&#39;Site&#39;,&#39;Type&#39;,&#39;Data.Source&#39;)) %&gt;% filter(UAA &gt; value+1000 &amp; UAA &lt; 10^5) %&gt;% mutate(index=1:n()) %&gt;% nest() %&gt;% mutate(incise=purrr::map(data,mycad.breaks)) %&gt;% unnest(incise) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(breaks=c(&#39;b2&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA) stemcad &lt;- cad %&gt;% left_join(incisioncad,by=c(&#39;Site&#39;,&#39;Type&#39;,&#39;Data.Source&#39;)) %&gt;% filter(UAA &gt; 10^5.3) %&gt;% mutate(index=1:n()) %&gt;% nest() %&gt;% mutate(incise=purrr::map(data,mycad.breaks)) %&gt;% unnest(incise) %&gt;% group_by(Data.Source,Site,Type) %&gt;% mutate(breaks=c(&#39;b3&#39;)) %&gt;% dplyr::select(Site,Type,Data.Source,breaks,value=UAA) cad.breaks &lt;- bind_rows(diffusecad,incisioncad,stemcad) %&gt;% ungroup() %&gt;% mutate(Site = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) cad.g &lt;- cad %&gt;% ungroup() %&gt;% mutate(Site = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) %&gt;% ggplot(.,aes(x=UAA,y=Cume_Freq,color=interaction(Data.Source,Type),size=Data.Source)) + geom_point(shape=1) + scale_size_manual(name=&#39;&#39;,guide=F,values=c(1.2,0.4)) + scale_x_log10(breaks=trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + scale_y_log10(limits=c(0.001,1),breaks=c(0.001,0.01,0.1,1)) + facet_grid(Type~Site) + geom_vline(data=cad.breaks,aes(xintercept=value,color=interaction(Data.Source,Type))) + theme(legend.position = &#39;top&#39;,legend.direction = &#39;horizontal&#39;) + scale_color_manual(name=&#39;Data Source&#39;,values=c(&#39;red&#39;,&#39;blue&#39;,&#39;orange3&#39;,&#39;purple4&#39;)) + ylab(&#39;P (A&gt;A*)&#39;) + xlab(expression(paste(&#39;Upslope Accumulated Area (&#39;,m^2,&#39;)&#39;))) png(filename=&#39;Figures2018/Fig5_CAD.All2decimals.png&#39;,width=10,height=6,units=&#39;in&#39;,res=300) cad.g dev.off() 7.2 UAA Density pdf(file=&#39;Figures2018/UAA.Density.pdf&#39;,width=10,height=5) cad %&gt;% ggplot(.,aes(x=UAA, fill=Data.Source)) + geom_density(alpha=0.5) + scale_x_log10() + scale_fill_manual(values=c(&#39;Red&#39;,&#39;Blue&#39;)) + facet_wrap(~Site,ncol=5) + theme(legend.position = &#39;top&#39;,legend.direction=&#39;horizontal&#39;) dev.off() "],
["energy-index.html", "8 Energy Index 8.1 Figure 6 EI Plots", " 8 Energy Index 8.1 Figure 6 EI Plots ei &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39;) %&gt;% dplyr::filter(Data!=&#39;Elev&#39;) %&gt;% #Sites less than 6km2 get smaller cut break select(Site,Type,Data,Data.Source,value,index) %&gt;% spread(key=Data,value) %&gt;% mutate(area.m2 = round(UAA*10,1)) %&gt;% mutate(ei=round(Slope*area.m2,1)) %&gt;% group_by(Site,Data.Source) %&gt;% mutate(ei.bins = cut(ei,breaks=unique(ei)))%&gt;% group_by(Site,Type,Data.Source,ei.bins) %&gt;% dplyr::summarize(UAA=mean(area.m2,na.rm=T), UAA.sd = sd(area.m2,na.rm=T), ei=round(mean(ei,na.rm=T),1)) %&gt;% group_by(Site,Type,Data.Source,ei) %&gt;% summarise(Freq=n()) %&gt;% arrange(Site,Type,Data.Source,desc(ei)) %&gt;% mutate(Cume_Freq=(cumsum(Freq)/sum(Freq))) %&gt;% mutate(revei=rev(ei)) ei.g &lt;- ei %&gt;% filter(ei &gt; 0.01) %&gt;% ungroup() %&gt;% mutate(Site = gsub(&#39;Ref&#39;,&#39;&#39;,Site)) %&gt;% ggplot(.,aes(x=ei,y=Cume_Freq,color=interaction(Data.Source,Type),size=Data.Source)) + geom_point(shape=1) + scale_size_manual(name=&#39;&#39;,guide=F,values=c(1.2,0.4)) + scale_x_log10(breaks=trans_breaks(&quot;log10&quot;, function(x) 10^x), labels = trans_format(&quot;log10&quot;, math_format(10^.x))) + scale_y_log10(limits=c(0.0005,1),breaks=c(0.001,0.01,0.1,1)) + facet_grid(Type~Site) + theme(legend.position = &#39;top&#39;,legend.direction = &#39;horizontal&#39;) + scale_color_manual(name=&#39;Data Source&#39;,values=c(&#39;red&#39;,&#39;blue&#39;,&#39;orange3&#39;,&#39;purple4&#39;)) + ylab(&#39;EI (EI&gt;EI*)&#39;) + xlab(expression(paste(&#39;Energy Index (S*A)&#39;))) ei.g png(filename=&#39;Figures2018/Fig_6_EI.Cume.png&#39;,width=10,height=6,units=&#39;in&#39;,res=300) ei.g dev.off() "],
["d-plots.html", "9 3D plots 9.1 Terrain metric drape 9.2 Draping zones over DEM 9.3 Distribution of process zones by site", " 9 3D plots 9.1 Terrain metric drape sites &lt;- names(all.list) #Get zlim values lim &lt;- function(x,y){ max1 &lt;- maxValue(x) min1 &lt;- minValue(x) max2 &lt;- maxValue(y) min2 &lt;- minValue(y) zlims &lt;-c(floor(min(c(min1,min2))),ceiling(max(c(max1,max2)))) return(zlims) } super_plotter &lt;- function(spruce = all.list[[10]], filename = filename){ newdem &lt;- spruce[[1]] olddem &lt;- spruce[[4]] newfac &lt;- spruce[[9]] oldfac &lt;- spruce[[10]] newslp &lt;- spruce[[5]] oldslp &lt;- spruce[[6]] newei &lt;- newfac*newslp oldei &lt;- oldfac*oldslp #Convert rasters to matrices old.s &lt;- as.matrix(oldslp) new.s &lt;- as.matrix(newslp) old.ei &lt;- log10(as.matrix(oldei)) new.ei &lt;- log10(as.matrix(newei)) old.ei[old.ei==-Inf] &lt;- -1 new.ei[new.ei==-Inf] &lt;- -1 old.m.na &lt;- as.matrix(olddem) new.m.na &lt;- as.matrix(newdem) olddem[is.na(olddem)] &lt;- minValue(olddem)-1 newdem[is.na(newdem)] &lt;- minValue(newdem)-1 old.m &lt;- as.matrix(olddem) new.m &lt;- as.matrix(newdem) old.f.m &lt;- log10(as.matrix(oldfac)) old.f.m[old.f.m==-Inf] &lt;- 1 new.f.m &lt;- log10(as.matrix(newfac)) new.f.m[new.f.m==-Inf] &lt;- 1 x &lt;- 1:nrow(old.m)*10 y &lt;- 1:ncol(old.m)*10 png(filename=filename,width=12,height=10,units=&#39;in&#39;,res=300) #Verbose code to get exactly the plot I want. cols &lt;-colorRampPalette(c(&#39;forestgreen&#39;,&#39;brown2&#39;)) bord &lt;- rgb(0,0,0,0) par(mar=c(0,0,2,0),mgp=c(1.8,0.5,0),cex=1.5,cex.lab=1.5,cex.axis=1.3) mx &lt;- matrix(c(1,1,2,2,3,4,4,5,5,6,7,7,8,8,9,10,10,11,11,12),4,5,byrow=T) layout(mx) #OldDEM l.dist &lt;- -0.05 theta &lt;- -90.5 phi &lt;- 45 shade=.65 lphi=0 ltheta=-135 # par(mfrow=c(1,2)) # hist(old.f.m,col=&#39;grey&#39;,ylim=c(0,6000),breaks=seq(0,7,by=.1)) # hist(new.f.m,col=&#39;grey&#39;,ylim=c(0,6000),breaks=seq(0,7,by=.1)) # zlims &lt;- lim(olddem,newdem) ## Old DEM, Top Left persp3D(x=x, y=y,z=old.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elev. (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=old.m.na,col=c(bord,cols(200)), colkey=list(side=4,line.clab=1,dist=l.dist,width=0.75,length=0.5,mgp=c(2,0.6,0)), lighting=T,add=T,clim=zlims,zlim=zlims,box=F, scale = FALSE, shade = 0.6,clab=&#39;Elev. (m)&#39;,expand=2, inttype=2) #NewDEM, Top Middle persp3D(x=x, y=y,z=new.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elev. (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=new.m.na,col=c(bord,cols(200)),colkey=list(plot=F), lighting=T,add=T,clim=zlims,zlim=zlims,box=F, scale = FALSE, shade = 0.6,clab=&#39;Elev. (m)&#39;,expand=2, inttype=2) area = round(length(new.m.na)/(10000),0) label = bquote(.(sites[i]) ~ &#39;-&#39; ~ .({area}) ~ km^2) mtext(label, side = 3, line = -1.5, cex = 2) #Elevation histogram, top right hist.mar &lt;- c(3,0,0.5,2) par(mar=hist.mar) hist(old.m.na,breaks=seq(zlims[1],zlims[2],length.out=50),xlim=zlims,col=&#39;blue&#39;,ylim=c(0,7000),xlab=&#39;Elevation (m)&#39;,ylab=&#39;Frequency&#39;,main=&#39;&#39;) reds2 &lt;- makeTransparent(&#39;red&#39;,alpha=.8) hist(new.m.na, breaks=seq(zlims[1],zlims[2],length.out=50),xlim=zlims,col=reds2,add=T,density=40) text(x = zlims[1]*1.1, y = 6000, labels = c(&#39;A&#39;), cex = 3) par(mar=c(0,0,0,0)) #OldSlope slims &lt;- c(0,2) scols &lt;- colorRampPalette(c(&#39;yellow3&#39;,&#39;red&#39;,&#39;red4&#39;)) persp3D(x=x, y=y,z=old.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=old.m.na,col=c(scols(200)),colvar = old.s, colkey=list(side=4,line.clab=1,dist=l.dist,width=0.75,length=0.5,mgp=c(2,0.6,0)), add=T,clim=slims,zlim=zlims,box=F,NAcol=bord, scale = FALSE,clab=&#39;Slope (m/m)&#39;,expand=2,shade=shade,lphi=lphi,ltheta=ltheta, inttype=2) #NewSlope persp3D(x=x, y=y,z=new.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=new.m.na,col=c(scols(200)),colvar=new.s,NAcol=bord, colkey=list(plot=F),add=T,zlim=zlims,box=F,shade=shade,lphi=lphi,ltheta=ltheta, scale = FALSE,clab=&#39;Slope (m/m)&#39;,expand=2,inttype=2,clims=slims) par(mar=hist.mar) if(sites[i] %in% c(&#39;WhiteOak&#39;, &#39;Laurel&#39;,&#39;Ben&#39;)){ hist(old.s,breaks=seq(0,4,length.out=150),xlim=c(0,1.2),col=&#39;blue&#39;,ylim=c(0,10000),xlab=&#39;Slope (m/m)&#39;,ylab=&#39;Frequency&#39;,main=&#39;&#39;) hist(new.s, breaks=seq(0,4,length.out=150),xlim=c(0,1.2),col=reds2,add=T,density=40) text(x = 0.1, y = 9000, labels = c(&#39;B&#39;), cex = 4) }else{ hist(old.s,breaks=seq(0,4,length.out=100),xlim=c(0,1.2),col=&#39;blue&#39;,ylim=c(0,8000),xlab=&#39;Slope (m/m)&#39;,ylab=&#39;Frequency&#39;,main=&#39;&#39;) hist(new.s, breaks=seq(0,4,length.out=100),xlim=c(0,1.2),col=reds2,add=T,density=40) text(x = 0.1, y = 7000, labels = c(&#39;B&#39;), cex = 3) } #OldFAC par(mar=c(0,0,0,0)) flims &lt;- log10(lim(newfac,oldfac)) cols.f &lt;- colorRampPalette(c(&#39;lightblue&#39;,&#39;darkblue&#39;,&#39;purple4&#39;,&#39;mediumvioletred&#39;)) persp3D(x=x, y=y,z=old.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=old.m.na,col=c(&#39;white&#39;,cols.f(50)),colvar=(old.f.m), colkey=list(side=4,line.clab=1,dist=l.dist,width=0.75,length=0.5,mgp=c(2,0.6,0)), add=T,zlim=zlims,box=F,shade=shade,lphi=lphi,ltheta=ltheta, scale = FALSE,clab=expression(bold(paste(&#39;Log UAA (&#39;,m^2,&#39;)&#39;,sep=&#39;&#39;))),expand=2,clims=flims, inttype=2) #NewFAC persp3D(x=x, y=y,z=new.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=new.m.na,col=c(&#39;white&#39;,cols.f(100)),colvar=new.f.m, colkey=list(plot=F),add=T,zlim=zlims,box=F, scale = FALSE,clab=&#39;&#39;,shade=shade,lphi=lphi,ltheta=ltheta, expand=2,inttype=2,clims=flims) old.f &lt;- 10^old.f.m par(mar=hist.mar) hist(old.f.m,breaks=seq(1,6.05,length.out=100),col=&#39;blue&#39;,ylim=c(0,8000), xlab=expression(paste(&#39;UAA (&#39;,m^2,&#39;)&#39;,sep=&#39;&#39;)),ylab=&#39;Frequency&#39;,main=&#39;&#39;,xaxt=&#39;n&#39;) axis(1,at=c(1,2,3,4,5,6),labels=c(expression(10^1),expression(10^2),expression(10^3),expression(10^4),expression(10^5),expression(10^6))) hist(new.f.m, breaks=seq(1,6.05,length.out=100),xlim=c(1,6),col=reds2,add=T,density=40) legend(x=3,y=4000,pch=c(15,15),col=c(&#39;blue&#39;,reds2),legend=c(&#39;Pre-Mining&#39;,&#39;Post-Mining&#39;),cex=1.5) text(x = 2, y = 7000, labels = c(&#39;C&#39;), cex = 3) #OldEI par(mar=c(0,0,0,0)) ei.lims &lt;- c(-2,5) ei.cols &lt;- colorRampPalette(c(&#39;tan2&#39;,&#39;tan4&#39;,&#39;cyan&#39;,&#39;blue&#39;,&#39;green&#39;,&#39;green&#39;)) persp3D(x=x, y=y,z=old.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=old.m.na,col=c(ei.cols(200)),colvar = old.ei,NAcols=bord, colkey=list(side=4,line.clab=1,dist=l.dist,width=0.75,length=0.5,mgp=c(2,0.6,0)), add=T,clim=ei.lims,zlim=zlims,box=F,NAcol=bord,shade=shade,lphi=lphi,ltheta=ltheta, scale = FALSE,clab=&#39;Log EI&#39;,expand=2, inttype=2) #NewEI #Shorten the color ramp new.ei[new.ei &lt; -2] &lt;- -2 persp3D(x=x, y=y,z=new.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elevation (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=new.m.na,col=c(ei.cols(200)),colvar=new.ei,NAcol=bord, colkey=list(plot=F),add=T,zlim=zlims,box=F,shade=shade,lphi=lphi,ltheta=ltheta, scale = FALSE,clab=&#39;Slope (m/m)&#39;,expand=2,inttype=2,clims=ei.lims) par(mar=hist.mar) hist(old.ei,breaks=seq(-2.1,6,length.out=100),col=&#39;blue&#39;,ylim=c(0,8000), xlab=&#39;Energy Index&#39;,ylab=&#39;Frequency&#39;,main=&#39;&#39;,xaxt=&#39;n&#39;) axis(1,at=c(-1,1,3,5,7),labels=c(expression(10^-1),expression(10^1),expression(10^3),expression(10^5),expression(10^7))) hist(new.ei, breaks=seq(-2.1,6,length.out=100),xlim=c(0,7.1),col=reds2,add=T,density=40) text(x = 0.01, y = 7000, labels = c(&#39;D&#39;), cex = 3) dev.off() } for(i in 1:length(sites)){ print(sites[i]) filename = paste0(&#39;Figures2018/3d_indices/&#39;,sites[i],&#39;_3D_4_indices.png&#39;) if(!file.exists(filename)){ super_plotter(all.list[[i]], filename) } } 9.2 Draping zones over DEM #Drape function names(all.list) drape &lt;- function(site = &#39;Spruce&#39;, filename = filename){ stack &lt;- all.list[[site]] newfac &lt;- stack[[9]] oldfac &lt;- stack[[10]] newdem &lt;- stack[[1]] olddem &lt;- stack[[4]] if(grepl(&#39;Ref&#39;,site)){ type = &#39;Unmined&#39; }else { type = &#39;Mined&#39; } if(site == &#39;WhiteRef&#39; &amp; type == &#39;Unmined&#39;){ site1 = &#39;WhiteOakRef&#39; }else{site1 = site} unique(sa.breaks$Site) sa.new &lt;- sa.breaks %&gt;% dplyr::filter(Site == site1, Type == type, Data.Source == &#39;Current&#39;) sa.old &lt;- sa.breaks %&gt;% dplyr::filter(Site == site1, Type==type, Data.Source == &#39;Historic&#39;) newzones &lt;- cut(newfac,breaks=c(0,sa.new$value/10,maxValue(newfac))) %&gt;% as.matrix(.) %&gt;% as.integer() oldzones &lt;- cut(oldfac,breaks=c(0,sa.old$value/10,maxValue(oldfac))) %&gt;% as.matrix(.) %&gt;% as.integer() zlims &lt;- lim(olddem,newdem) zone.cols &lt;- rev(RColorBrewer::brewer.pal(4,&#39;BrBG&#39;)) #OldDEM l.dist &lt;- -0.05 theta &lt;- -90.5 phi &lt;- 45 shade=.65 lphi=0 ltheta=-135 old.m.na &lt;- as.matrix(olddem) new.m.na &lt;- as.matrix(newdem) olddem[is.na(olddem)] &lt;- minValue(olddem)-1 newdem[is.na(newdem)] &lt;- minValue(newdem)-1 old.m &lt;- as.matrix(olddem) new.m &lt;- as.matrix(newdem) x &lt;- 1:nrow(old.m)*10 y &lt;- 1:ncol(old.m)*10 png(filename=filename,width=9,height=4,units=&#39;in&#39;,res=300) par(mar=c(0,0,0,0),mgp=c(1.8,0.5,0),cex=1.5,cex.lab=1.5,cex.axis=1.3) mx1 &lt;- matrix(c(1,1,1,2,2,2,3,3),1,8,byrow=T) layout(mx1) ## Old Zones, Top Left persp3D(x=x, y=y,z=old.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elev. (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=old.m.na,col=zone.cols, colkey=list(side=4,line.clab=1,dist=l.dist,width=0.75,length=0.5,mgp=c(2,0.6,0),at=1:4), lighting=F,add=T,zlim=zlims,box=F, scale = FALSE, shade = 0.6,clab=&#39;Domain&#39;,expand=2, inttype=2,colvar=oldzones) #New zones persp3D(x=x, y=y,z=new.m,col=c(&#39;gray30&#39;),lighting=T,colkey=list(plot=FALSE),theta=theta,phi=phi, scale = FALSE, shade = 1,clab=&#39;Elev. (m)&#39;,axes=F,zlim=zlims,box=F, ticktype=&#39;detailed&#39;,xlab=&#39;North (m)&#39;,ylab=&#39;East (m)&#39;,zlab=&#39;Elev (m)&#39;,inttype=2,expand=2) persp3D(x=x, y=y,z=new.m.na,col=zone.cols, colkey=list(plot=F), lighting=F,add=T,zlim=zlims,box=F, scale = FALSE, shade = 0.6,clab=&#39;Domain&#39;,expand=2, inttype=2,colvar=newzones) area = round(length(new.m.na)/(10000),0) label = bquote(.(sites[i]) ~ &#39;-&#39; ~ .({area}) ~ km^2) if(site != &#39;Spruce&#39;){ mtext(label, side = 3, line = -3, cex = 1) } ## Count histogram hmax = ceiling(max(c(table(newzones),table(oldzones)))/10000)*10000 hseq = seq(0,hmax,length.out = 3) par(mar=c(3,4,3,1)) hist(oldzones,col=&#39;blue&#39;, xlab=&#39;Domain&#39;, ylab=expression(paste(&#39;Area (&#39;,km^2,&#39;)&#39;)), main=&#39;&#39;,xaxt=&#39;n&#39;,yaxt=&#39;n&#39;, ylim = c(0,hmax)) axis(1,at=c(1,2,3,4),padj=0,line=-.8) axis(2, at = hseq,labels = round(hseq/10000,1)) hist(newzones,col=reds2, xlab=&#39;Domain&#39;,ylab=&#39;Frequency&#39;,main=&#39;&#39;,xaxt=&#39;n&#39;,density=40,add=T) legend(x=2.2,y=30000,pch=c(15,15),col=c(&#39;gray20&#39;,reds2),legend=c(&#39;Pre-Mining&#39;,&#39;Post-Mining&#39;)) dev.off() } for(i in 1:length(sites)){ print(sites[i]) filename = paste0(&#39;Figures2018/3d_drape/&#39;,sites[i],&#39;Zone_Drape.png&#39;) if(!file.exists(filename)){ drape(site = sites[i], filename) } } 9.3 Distribution of process zones by site sa.break.wide &lt;- sa.breaks %&gt;% rename(Watershed=Site) %&gt;% group_by(Watershed,Type,Data.Source) %&gt;% nest() %&gt;% rename(break.data=data) sa.cutter &lt;- function(x,y){ df &lt;- x %&gt;% mutate(zones=cut(x$area.m2,breaks=c(0,y$value,max(x$area.m2)), labels=c(&#39;I&#39;,&#39;II&#39;,&#39;III&#39;,&#39;IV&#39;))) return(df) } sa.zones &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39;) %&gt;% dplyr::filter(Data==&#39;UAA&#39;) %&gt;% select(Site,UAA=value,Watershed,Type,Data.Source) %&gt;% mutate(area.m2 = round(UAA*10,2)) %&gt;% group_by(Watershed,Type,Data.Source) %&gt;% nest() %&gt;% left_join(sa.break.wide,by=c(&#39;Watershed&#39;,&#39;Type&#39;,&#39;Data.Source&#39;)) %&gt;% mutate(cut.df = map2(data,break.data,sa.cutter)) %&gt;% unnest(cut.df) %&gt;% ungroup() %&gt;% group_by(Watershed,Type,Data.Source,zones)%&gt;% summarize(area.km2 = n()/10000) %&gt;% ungroup() sa.zones %&gt;% ggplot(aes(x=zones,y=area.km2,fill=interaction(Data.Source,Type))) + geom_bar(stat=&#39;identity&#39;,position=&#39;dodge&#39;) + facet_grid(Type~Watershed) + scale_fill_manual(name=&#39;Data Source&#39;,values=c(&#39;red&#39;,&#39;blue&#39;,&#39;Orange3&#39;,&#39;Purple4&#39;)) + theme(legend.position=&#39;top&#39;,legend.direction=&#39;horizontal&#39;) "],
["table-of-stats-by-zone.html", "10 Table of stats by zone", " 10 Table of stats by zone elev &lt;- long.df %&gt;% filter(fdr.type == &#39;None&#39;, Data == &#39;Elev&#39;) %&gt;% select(index,Site,Elev = value,Watershed,Type,Data,Data.Source) sa.zones_stats &lt;- long.df %&gt;% dplyr::filter(fdr.type ==&#39;f.inf&#39;) %&gt;% select(index,Site,value,Watershed,Type,Data,Data.Source) %&gt;% pivot_wider(names_from = Data) %&gt;% left_join(elev) %&gt;% mutate(area.m2 = round(UAA*10,2)) %&gt;% group_by(Watershed,Type,Data.Source) %&gt;% nest() %&gt;% left_join(sa.break.wide,by=c(&#39;Watershed&#39;,&#39;Type&#39;,&#39;Data.Source&#39;)) %&gt;% mutate(cut.df = map2(data,break.data,sa.cutter)) %&gt;% unnest(cut.df) %&gt;% ungroup() %&gt;% group_by(Watershed, Type,Data.Source,zones) %&gt;% summarize(area.km2 = n()/10000, mean_elev = mean(Elev), median_slope = median(Slope), count = n()) %&gt;% ungroup() sa.zones_stats write_csv(sa.zones_stats,&#39;Figures2018/zonal_stats.csv&#39;) wide_slope &lt;- sa.zones_stats %&gt;% select(Watershed, Type, Data.Source, zones, median_slope) %&gt;% mutate(median_slope = round(median_slope,2)) %&gt;% pivot_wider(names_from = Data.Source, values_from = median_slope) %&gt;% mutate(percent_change = round(100*((Current - Historic)/Historic),0)) %&gt;% mutate(slope = paste0(Historic,&#39;-&#39;,Current,&#39; (&#39;,percent_change,&#39;%)&#39;)) %&gt;% select(Watershed, zones, Type, slope) %&gt;% mutate(zones = as.character(zones)) %&gt;% pivot_longer(cols = slope) %&gt;% pivot_wider(names_from = zones) %&gt;% select(-name) write_csv(wide_slope, &#39;Figures2018/zone_slope_stats.csv&#39;) "],
["statistical-tests.html", "11 Statistical tests", " 11 Statistical tests s.uaa.wide &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;f.inf&#39; | fdr.type==&#39;None&#39;) %&gt;% select(-fdr.type,-Key,-shed.type,-elev.data) %&gt;% spread(key=Data,value=value) elev.wide &lt;- long.df %&gt;% dplyr::filter(fdr.type==&#39;None&#39;) %&gt;% filter(shed.type == &#39;old&#39;) %&gt;% #Only looking at elevation profile changes with old watershed outline select(-fdr.type,-Key,-shed.type) %&gt;% spread(key=Data,value=value) %&gt;% mutate(Data.Source=ifelse(elev.data==&#39;New&#39;,&#39;Current&#39;,&#39;Historic&#39;)) %&gt;% select(-elev.data) all.dat &lt;- left_join(s.uaa.wide,elev.wide, by=c(&#39;index&#39;,&#39;Site&#39;,&#39;Data.Source&#39;,&#39;Type&#39;,&#39;Watershed&#39;)) df &lt;- all.dat ks.func &lt;- function(df,column) { wider &lt;- df %&gt;% spread(key=Data.Source,value=!!column) ks.mod &lt;- ks.test(wider$Historic,wider$Current) %&gt;% glance(.) %&gt;% mutate(Source=column) return(ks.mod) } column = quo(Elev) ks.tester &lt;- function(df,column=&#39;Elev&#39;){ all.dat %&gt;% group_by(Watershed,Type) %&gt;% nest() %&gt;% mutate(ks.mods = purrr::map(data,ks.func,column)) %&gt;% unnest(ks.mods) %&gt;% dplyr::select(-data,-alternative) %&gt;% return(.) } elev.ks &lt;- ks.tester(all.dat,column=&#39;Elev&#39;) slope.ks &lt;- ks.tester(all.dat,column=&#39;Slope&#39;) uaa.ks &lt;- ks.tester(all.dat,column=&#39;UAA&#39;) all.ks &lt;- rbind(elev.ks,slope.ks,uaa.ks) write_csv(all.ks,path=&#39;Figures2018/kstests.csv&#39;) "],
["supplemental-informatino.html", "12 Supplemental informatino", " 12 Supplemental informatino "],
["supplement-way-too-much-detail.html", "13 Supplement way too much detail 13.1 Check for differences between flow direction algorithm (f8 or f.infinity)", " 13 Supplement way too much detail 13.1 Check for differences between flow direction algorithm (f8 or f.infinity) 13.1.1 Flow direction differnces in Uplsope Accumulated Area (UAA) for reference sites load(&#39;UAA.E.Slope.Ref.RData&#39;) load(&#39;ras.stack.ref.RData&#39;) load(&#39;Long.DF.RData&#39;) #Elevation is not impacted. fdr.diff &lt;- long.df %&gt;% filter(Data != &#39;Elev&#39;) %&gt;% select(Watershed,Site,Data,Data.Source,fdr.type,value,index,Type) %&gt;% spread(key=fdr.type,value=value) %&gt;% group_by(Watershed,Data,Data.Source) %&gt;% #Account for the difference in pixel counting methods by dividng f.inf by 10 for UAA mutate(f.inf.cor=ifelse(Data == &#39;UAA&#39;,f.inf/10,f.inf)) %&gt;% mutate(fdr.dif=f.8-f.inf) %&gt;% #Filter out errors where watershed sizes differ giving very large FDR differences filter(fdr.dif &gt; -500 &amp; fdr.dif &lt; 500) %&gt;% ungroup(.) fdr.diff %&gt;% filter(Data == &#39;UAA&#39;) %&gt;% ggplot(.,aes(x=fdr.dif,color=Data.Source)) + stat_density(geom=&#39;line&#39;,size=1.2) + facet_wrap(~Watershed + Type,scales=&#39;fixed&#39;) + xlab(&#39;Flow Accumulation Difference in m2 (F.8-F.Inf)&#39;) + theme(legend.position=c(.8,.15)) + scale_color_manual(values=c(&#39;#762a83&#39;,&#39;#1b7837&#39;,&#39;#b2182b&#39;,&#39;#2166ac&#39;)) 13.1.2 Flow Direction Differences in Slope fdr.diff %&gt;% filter(Data == &#39;Slope&#39;) %&gt;% ggplot(.,aes(x=fdr.dif,color=Data.Source)) + stat_density(geom=&#39;line&#39;,size=1.2) + facet_wrap(~Watershed + Type,scales=&#39;fixed&#39;) + xlab(&#39;Slope in m/m (F.8-F.Inf)&#39;) + theme(legend.position=c(.8,.2)) + scale_color_manual(values=c(&#39;#762a83&#39;,&#39;#1b7837&#39;,&#39;#b2182b&#39;,&#39;#2166ac&#39;)) Four process domains based on slope-area plots identified geographically on DEM of unmined and MTM-landscape at all nine study sites not shown in paper. Figures below include abbreviated site names and (watershed area in \\(km^2\\)) DEM and distributions of select terrain metrics that include elevation, slope, accumulated area, and slope-area product as a proxy for stream power for the historic and contemporary time periods at all nine study sites not shown in paper. Same figure as Figure 7 in main text. Figures below include abbreviated site names and (watershed area in \\(km^2\\)) "]
]
